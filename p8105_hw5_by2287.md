Iterations
================
Binyam Yilma
11/16/2020

## Problem 1

Import + Tidy

``` r
homicide_df = 
  read_csv("./data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  filter(city_state != "Tulsa_AL") #filter out Tulsa_AL because it only contains one observation - probably a data entry mistake
```

The dataframe `homicide_df` contains information on homicides in 50
large U.S. cities. The dataset contains52178 rows and 14 columns, which
contain information such as:reported\_date, city, state, victim\_race,
victim\_age, disposition.

``` r
aggregate_df = homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
   `total_homicide` = n(),
   `num_unsolved` = sum(resolved == "unsolved")
  ) 

aggregate_df %>% 
  head(5) %>% 
    knitr::kable()
```

| city\_state     | total\_homicide | num\_unsolved |
| :-------------- | --------------: | ------------: |
| Albuquerque\_NM |             378 |           146 |
| Atlanta\_GA     |             973 |           373 |
| Baltimore\_MD   |            2827 |          1825 |
| Baton Rouge\_LA |             424 |           196 |
| Birmingham\_AL  |             800 |           347 |

``` r
p_test = prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(num_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(total_homicide)
  ) %>% 
  broom::tidy() %>% select(estimate, conf.low, conf.high)


p_test %>% 
  knitr::kable()
```

|  estimate |  conf.low | conf.high |
| --------: | --------: | --------: |
| 0.6455607 | 0.6275625 | 0.6631599 |

``` r
prop_test = aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = num_unsolved, .y = total_homicide, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

Making a plot of the proption test estimates, with confidence intervals,
by city. The proportion test here tests whether the proportion of
unsolved homicide cases is equal to the proprtion of solved homicide
cases.

``` r
prop_test %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 60, vjust = 1.0, hjust = 1)) + 
  labs(
    title = "Proportion Test Estimates, by City",
    x = "City",
    y = "Proportion Estimate"
  )
```

<img src="p8105_hw5_by2287_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />

We notice that the `Chicago_IL` has the highest number of unsolved
homicide cases, followed up `New_Orleans_LA`. By contrast, `Richmond_VA`
has the lowest unsolved homicide rate, followed by `Charlotte_NC`.

## Problem 2

``` r
lda = tibble(
    path = list.files("./data/lda_data"),
  ) %>% 
  mutate(
    id = str_remove(path, ".csv"),
    path = str_c("./data/lda_data/", path),
    data = map(path, read_csv),
    data = map(data, bind_rows)
    ) %>% 
    select(-path) %>% 
    separate(id, into = c("treatment", "id"), sep = "_") %>% 
  unnest(data) %>% 
    relocate(id) %>% 
  pivot_longer(
    cols = week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "observation"
  )
    

lda %>% 
  head(5) %>% 
  knitr::kable()
```

| id | treatment | week | observation |
| :- | :-------- | :--- | ----------: |
| 01 | con       | 1    |        0.20 |
| 01 | con       | 2    |      \-1.31 |
| 01 | con       | 3    |        0.66 |
| 01 | con       | 4    |        1.96 |
| 01 | con       | 5    |        0.23 |

The dataset `lda` is tidy data that contains data from a longitudinal
study on 160 participants, including the subject ID, arm, and
observations over time

## Problem 3

First, I define a function `ttest` that outputs the results of a
one-sample t-test, in specific the estimated mu\_hat & p-value from
number generated from a random normal distrbution, with a fixed sample
size `samp_size` of 30 and a standard deviation `sigma` of 5.

``` r
ttest = function(mu, samp_size = 30, sigma = 5) {
  sim_data = 
    tibble(
      x = rnorm(n = samp_size, mean = mu, sd = sigma)
    )
  
   sim_data %>% 
     summarize(
       mu_hat = t.test(x) %>% broom::tidy() %>% pull(estimate),
       p_value = t.test(x) %>% broom::tidy() %>% pull(p.value)
       
    )
}
```

Here, I create a dataframe that simulates the 5000 samples of size `30`
and standard deviation of `5` form the random normal distribution. Then,
I perform a one-sample ttest on these samples, and extract the estimate
`mu_hat` and the `p_value` from each of these samples. I save these
results in the dataframe `ttest_results`.

``` r
ttest_results = tibble(
  mu = c(0,1,2,3,4,5,6)
) %>% 
  mutate(
    output_lists = map(.x = mu, ~rerun(5000, ttest(.x))),
    estimate_df = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(estimate_df) 
```

#### Plots

In the plot below, we see that the power of a test has a sigmoidal
relationship with the effect size, as effect size increases so does
power, up to an extent, then it starts to plateau.

``` r
ttest_results %>% 
  group_by(mu) %>% 
  summarize(
    total = n(), 
    num_rejected = sum(p_value < 0.05), 
    prop_rejected = num_rejected/total
  ) %>% 
  ggplot(aes(x = mu, y = prop_rejected)) + 
  geom_point() + 
  geom_smooth(se = F) + 
  labs(
    title = "Power Vs. Effect Size",
    x = "True Population Mean",
    y = "Power"
  )
```

<img src="p8105_hw5_by2287_files/figure-gfm/unnamed-chunk-10-1.png" width="90%" />

``` r
#create a df that only filters on those tests whose H0 were rejected (p-value < 0.05)

ttest_results2 = ttest_results %>% 
  filter(p_value < 0.05) %>% 
  group_by(mu) %>% 
  summarize(
    mean_mu_hat = mean(mu_hat)
  ) 


#plot a line that shows the relationship between the average estimate mu_hat & the true mean mu overall, as well as for those tests with p-values less than 0.05
ttest_results %>% 
  group_by(mu) %>% 
  summarize(
    mean_mu_hat = mean(mu_hat)
  ) %>% 
  ggplot(aes(y = mean_mu_hat, x = mu)) + 
  geom_line() + 
  geom_point() +
    geom_line(data = ttest_results2, color = "red") +
    geom_point(data = ttest_results2, color = "red") + 
  labs(
    title = "Mean of Estimate Vs. True Mean",
    x = "True Population Mean",
    y = "Mean of Estimate",
    caption = "Red Line shows those tests with Rejected Null Ho"
  )
```

<img src="p8105_hw5_by2287_files/figure-gfm/unnamed-chunk-11-1.png" width="90%" />
